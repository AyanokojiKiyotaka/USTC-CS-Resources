{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well i'm not sure about the story nad it did seem biased. What\n",
      "I disagree with is your statement that the U.S. Media is out to\n",
      "ruin Israels reputation. That is rediculous. The U.S. media is\n",
      "the most pro-israeli media in the world. Having lived in Europe\n",
      "I realize that incidences such as the one described in the\n",
      "letter have occured. The U.S. media as a whole seem to try to\n",
      "ignore them. The U.S. is subsidizing Israels existance and the\n",
      "Europeans are not (at least not to the same degree). So I think\n",
      "that might be a reason they report more clearly on the\n",
      "atrocities.\n",
      "\tWhat is a shame is that in Austria, daily reports of\n",
      "the inhuman acts commited by Israeli soldiers and the blessing\n",
      "received from the Government makes some of the Holocaust guilt\n",
      "go away. After all, look how the Jews are treating other races\n",
      "when they got power. It is unfortunate.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Well',\n",
       " 'i',\n",
       " \"'m\",\n",
       " 'not',\n",
       " 'sure',\n",
       " 'about',\n",
       " 'the',\n",
       " 'story',\n",
       " 'nad',\n",
       " 'it',\n",
       " 'did',\n",
       " 'seem',\n",
       " 'biased',\n",
       " '.',\n",
       " 'What',\n",
       " 'I',\n",
       " 'disagree',\n",
       " 'with',\n",
       " 'is',\n",
       " 'your',\n",
       " 'statement',\n",
       " 'that',\n",
       " 'the',\n",
       " 'U.S.',\n",
       " 'Media',\n",
       " 'is',\n",
       " 'out',\n",
       " 'to',\n",
       " 'ruin',\n",
       " 'Israels',\n",
       " 'reputation',\n",
       " '.',\n",
       " 'That',\n",
       " 'is',\n",
       " 'rediculous',\n",
       " '.',\n",
       " 'The',\n",
       " 'U.S.',\n",
       " 'media',\n",
       " 'is',\n",
       " 'the',\n",
       " 'most',\n",
       " 'pro-israeli',\n",
       " 'media',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Having',\n",
       " 'lived',\n",
       " 'in',\n",
       " 'Europe',\n",
       " 'I',\n",
       " 'realize',\n",
       " 'that',\n",
       " 'incidences',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'one',\n",
       " 'described',\n",
       " 'in',\n",
       " 'the',\n",
       " 'letter',\n",
       " 'have',\n",
       " 'occured',\n",
       " '.',\n",
       " 'The',\n",
       " 'U.S.',\n",
       " 'media',\n",
       " 'as',\n",
       " 'a',\n",
       " 'whole',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'try',\n",
       " 'to',\n",
       " 'ignore',\n",
       " 'them',\n",
       " '.',\n",
       " 'The',\n",
       " 'U.S.',\n",
       " 'is',\n",
       " 'subsidizing',\n",
       " 'Israels',\n",
       " 'existance',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Europeans',\n",
       " 'are',\n",
       " 'not',\n",
       " '(',\n",
       " 'at',\n",
       " 'least',\n",
       " 'not',\n",
       " 'to',\n",
       " 'the',\n",
       " 'same',\n",
       " 'degree',\n",
       " ')',\n",
       " '.',\n",
       " 'So',\n",
       " 'I',\n",
       " 'think',\n",
       " 'that',\n",
       " 'might',\n",
       " 'be',\n",
       " 'a',\n",
       " 'reason',\n",
       " 'they',\n",
       " 'report',\n",
       " 'more',\n",
       " 'clearly',\n",
       " 'on',\n",
       " 'the',\n",
       " 'atrocities',\n",
       " '.',\n",
       " 'What',\n",
       " 'is',\n",
       " 'a',\n",
       " 'shame',\n",
       " 'is',\n",
       " 'that',\n",
       " 'in',\n",
       " 'Austria',\n",
       " ',',\n",
       " 'daily',\n",
       " 'reports',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inhuman',\n",
       " 'acts',\n",
       " 'commited',\n",
       " 'by',\n",
       " 'Israeli',\n",
       " 'soldiers',\n",
       " 'and',\n",
       " 'the',\n",
       " 'blessing',\n",
       " 'received',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Government',\n",
       " 'makes',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Holocaust',\n",
       " 'guilt',\n",
       " 'go',\n",
       " 'away',\n",
       " '.',\n",
       " 'After',\n",
       " 'all',\n",
       " ',',\n",
       " 'look',\n",
       " 'how',\n",
       " 'the',\n",
       " 'Jews',\n",
       " 'are',\n",
       " 'treating',\n",
       " 'other',\n",
       " 'races',\n",
       " 'when',\n",
       " 'they',\n",
       " 'got',\n",
       " 'power',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'unfortunate',\n",
       " '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text_list = np.load(\"text.npy\")\n",
    "print(text_list[0])\n",
    "\n",
    "import nltk\n",
    "nltk.word_tokenize(text_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Well', 'i', \"'m\", 'not', 'sure', 'about', 'the', 'story', 'nad', 'it', 'did', 'seem', 'biased', '.', 'What', 'I', 'disagree', 'with', 'is', 'your', 'statement', 'that', 'the', 'U.S.', 'Media', 'is', 'out', 'to', 'ruin', 'Israels', 'reputation', '.', 'That', 'is', 'rediculous', '.', 'The', 'U.S.', 'media', 'is', 'the', 'most', 'pro-israeli', 'media', 'in', 'the', 'world', '.', 'Having', 'lived', 'in', 'Europe', 'I', 'realize', 'that', 'incidences', 'such', 'as', 'the', 'one', 'described', 'in', 'the', 'letter', 'have', 'occured', '.', 'The', 'U.S.', 'media', 'as', 'a', 'whole', 'seem', 'to', 'try', 'to', 'ignore', 'them', '.', 'The', 'U.S.', 'is', 'subsidizing', 'Israels', 'existance', 'and', 'the', 'Europeans', 'are', 'not', '(', 'at', 'least', 'not', 'to', 'the', 'same', 'degree', ')', '.', 'So', 'I', 'think', 'that', 'might', 'be', 'a', 'reason', 'they', 'report', 'more', 'clearly', 'on', 'the', 'atrocities', '.', 'What', 'is', 'a', 'shame', 'is', 'that', 'in', 'Austria', ',', 'daily', 'reports', 'of', 'the', 'inhuman', 'acts', 'commited', 'by', 'Israeli', 'soldiers', 'and', 'the', 'blessing', 'received', 'from', 'the', 'Government', 'makes', 'some', 'of', 'the', 'Holocaust', 'guilt', 'go', 'away', '.', 'After', 'all', ',', 'look', 'how', 'the', 'Jews', 'are', 'treating', 'other', 'races', 'when', 'they', 'got', 'power', '.', 'It', 'is', 'unfortunate', '.']\n",
      "[('.', 11), ('U.S.', 4), ('I', 3), ('The', 3), ('media', 3), ('seem', 2), ('What', 2), ('Israels', 2), (',', 2), ('Well', 1), (\"'m\", 1), ('sure', 1), ('story', 1), ('nad', 1), ('biased', 1), ('disagree', 1), ('statement', 1), ('Media', 1), ('ruin', 1), ('reputation', 1), ('That', 1), ('rediculous', 1), ('pro-israeli', 1), ('world', 1), ('Having', 1), ('lived', 1), ('Europe', 1), ('realize', 1), ('incidences', 1), ('one', 1), ('described', 1), ('letter', 1), ('occured', 1), ('whole', 1), ('try', 1), ('ignore', 1), ('subsidizing', 1), ('existance', 1), ('Europeans', 1), ('(', 1), ('least', 1), ('degree', 1), (')', 1), ('So', 1), ('think', 1), ('might', 1), ('reason', 1), ('report', 1), ('clearly', 1), ('atrocities', 1)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "punctuations = {'(', ')', '{', '}', '[', ']', '\"', \"'\",\n",
    "                ',', ';', '.', '!', '?'}\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, text_list):\n",
    "        self.text_list = text_list\n",
    "        self.stopwords_set = set(stopwords.words('english'))\n",
    "        self.preprocess()\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_dictionary(self, text_list):\n",
    "        dictionary = set()\n",
    "        \n",
    "    def preprocess(self):\n",
    "        doc_list = []\n",
    "        for text in self.text_list:\n",
    "            words = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "            print(words)\n",
    "            if words[-1] == '':\n",
    "                words = words[:-1]\n",
    "            words = [word for word in words if word not in self.stopwords_set]\n",
    "            print(nltk.FreqDist(words).most_common(50))\n",
    "            break\n",
    "dataset = Dataset(text_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. transform data into bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_bof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
